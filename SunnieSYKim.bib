%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% preprints
%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{ramaswamy2023ufo,
author = {Vikram V. Ramaswamy and Sunnie S. Y. Kim and Nicole Meister and Ruth Fong and Olga Russakovsky},
title = {{UFO}: A Unified Method for Controlling Understandability and Faithfulness Objectives in Concept-based Explanations for CNNs},
journal = {arXiv:2303.15632},
year = {2023}
}

@article{ramaswamy2022elude,
author = {Vikram V. Ramaswamy and Sunnie S. Y. Kim and Nicole Meister and Ruth Fong and Olga Russakovsky},
title = {{ELUDE}: Generating interpretable explanations via a decomposition into labelled and unlabelled features},
journal = {arXiv:2206.07690},
year = {2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% published/accepted
%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{kim2023trust,
author = {Sunnie S. Y. Kim and Elizabeth Anne Watkins and Olga Russakovsky and Ruth Fong and Andrés Monroy-Hernández},
title = {Humans, {AI}, and Context: Understanding End-Users’ Trust in a Real-World Computer Vision Application},
booktitle = {To appear in ACM Conference on Fairness, Accountability, and Transparency (FAccT)},
year = {2023}
}

@inproceedings{ramaswamy2023overlookedfactors,
author = {Vikram V. Ramaswamy and Sunnie S. Y. Kim and Ruth Fong and Olga Russakovsky},
title = {Overlooked Factors in Concept-based Explanations: Dataset Choice, Concept Learnability, and Human Capability},
booktitle = {To appear in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2023}
}

@inproceedings{kim2023helpmehelptheai,
author = {Sunnie S. Y. Kim and Elizabeth Anne Watkins and Olga Russakovsky and Ruth Fong and Andrés Monroy-Hernández},
title = {"Help Me Help the {AI}": Understanding How Explainability Can Support Human-{AI} Interaction},
booktitle = {ACM Conference on Human Factors in Computing Systems (CHI)},
year = {2023}
}

@misc{kim2022hcai,
author = {Sunnie S. Y. Kim and Elizabeth Anne Watkins and Olga Russakovsky and Ruth Fong and Andrés Monroy-Hernández},
title = {Closing the Creator-Consumer Gap in {XAI}: A Call for Participatory {XAI} Design with End-users},
journal = {NeurIPS 2022 Human-Centered AI (HCAI) Workshop},
year = {2022}
}

@inproceedings{kim2022hive,
author = {Sunnie S. Y. Kim and Nicole Meister and Vikram V. Ramaswamy and Ruth Fong and Olga Russakovsky},
title = {{HIVE}: Evaluating the Human Interpretability of Visual Explanations},
booktitle = {European Conference on Computer Vision (ECCV)},
year={2022}
}

@article {zhou2022loom,
article_type = {journal},
title = {Shallow neural networks trained to detect collisions recover features of visual loom-selective neurons},
author = {Zhou, Baohua and Li, Zifan and Kim, Sunnie and Lafferty, John and Clark, Damon A},
editor = {Rieke, Fred},
volume = 11,
year = 2022,
month = {jan},
pub_date = {2022-01-13},
pages = {e72067},
citation = {eLife 2022;11:e72067},
doi = {10.7554/eLife.72067},
url = {https://doi.org/10.7554/eLife.72067},
abstract = {Animals have evolved sophisticated visual circuits to solve a vital inference problem: detecting whether or not a visual signal corresponds to an object on a collision course. Such events are detected by specific circuits sensitive to visual looming, or objects increasing in size. Various computational models have been developed for these circuits, but how the collision-detection inference problem itself shapes the computational structures of these circuits remains unknown. Here, inspired by the distinctive structures of LPLC2 neurons in the visual system of Drosophila, we build anatomically-constrained shallow neural network models and train them to identify visual signals that correspond to impending collisions. Surprisingly, the optimization arrives at two distinct, opposing solutions, only one of which matches the actual dendritic weighting of LPLC2 neurons. Both solutions can solve the inference problem with high accuracy when the population size is large enough. The LPLC2-like solutions reproduces experimentally observed LPLC2 neuron responses for many stimuli, and reproduces canonical tuning of loom sensitive neurons, even though the models are never trained on neural data. Thus, LPLC2 neuron properties and tuning are predicted by optimizing an anatomically-constrained neural network to detect impending collisions. More generally, these results illustrate how optimizing inference tasks that are important for an animal's perceptual goals can reveal and explain computational properties of specific sensory neurons.},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{kim2021re,
title = {[{R}e] {D}on't Judge an Object by Its Context: Learning to Overcome Contextual Bias},
author = {Sunnie S. Y. Kim and Sharon Zhang and Nicole Meister and Olga Russakovsky},
journal = {ReScience C},
year = {2021},
volume={7},
issue={2}
}

@inproceedings{ramaswamy2021debiasing,
author = {Vikram V. Ramaswamy and Sunnie S. Y. Kim and Olga Russakovsky},
title = {Fair Attribute Classification through Latent Space De-biasing},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2021}
}

@inproceedings{savarese2021iem,
author = {Pedro Savarese and Sunnie S. Y. Kim and Michael Maire and Gregory Shakhnarovich and David McAllester},
title = {Information-Theoretic Segmentation by Inpainting Error Maximization},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2021}
}

@misc{nguyen2021imet,
author = {Vivien Nguyen and Sunnie S. Y. Kim},
title = {Cleaning and Structuring the Label Space of the iMet Collection 2020},
booktitle = {CVPR 2021 Fine-Grained Visual Categorization (FGVC) Workshop},
year = {2021}
}

@inproceedings{kim2020dst,
author = {Sunnie S. Y. Kim and Nicholas Kolkin and Jason Salavon and Gregory Shakhnarovich},
title = {Deformable Style Transfer},
booktitle = {European Conference on Computer Vision (ECCV)}
year = {2020}
}
